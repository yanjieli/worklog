## 一、什么是大数据？核心问题

​	1、举例：（1）商品推荐  （问题1）大量的订单如何存储？
​	                        （问题2）大量的订单如何计算？
​			 （2）天气预报  （问题1）大量的天气数据如何存储？
​			                （问题2）大量的天气数据如何计算？
​							

	2、核心问题：（1）数据的存储：分布式文件系统
	             （2）数据的计算：分布式计算
				                  （方向一）离线计算：MapReduce、Spark Core、Flink DataSet
								  （方向二）实时计算：Storm、Spark Streaming、Flink DataStream

## 二、什么是数据仓库？

​	1、本质就是一个数据库
​	2、Hadoop、Spark、FLink都可以看成是数据仓库的一种实现方式。

## 三、OLTP与OLAP

​	OLTP：online transaction processing 联机事物处理
​	OLAP：online analytic processing       联机分析处理

## 四、Google的三驾马车（三篇论文）：重点

​	1、GFS：google file system ---> HDFS：Hadoop Distributed File System
​	2、MapReduce计算模型：问题来源PageRank：网页排名
​	3、BigTable大表：NoSQL数据库HBase
​		（*）复习：RDBMS、范式（减少数据冗余。降低性能）
​		（*）大表：把所有的数据存入一张表

## 五、搭建Hadoop环境

​	准备工作：
​	（*）关闭防火墙
​		[root@bigdata11 ~]# systemctl stop firewalld.service
​		[root@bigdata11 ~]# systemctl disable firewalld.service
​		

	（*）设置主机名 vi /etc/hosts
			192.168.157.11 bigdata11
	
	（*）安装JDK
			tar -zxvf jdk-8u181-linux-x64.tar.gz -C ~/training/
			vi ~/.bash_profile
				JAVA_HOME=/root/training/jdk1.8.0_181
				export JAVA_HOME
	
				PATH=$JAVA_HOME/bin:$PATH
				export PATH
			生效环境变量
			source ~/.bash_profile
	
	（*）Hadoop的目录结构
		 vi ~/.bash_profile
			HADOOP_HOME=/root/training/hadoop-2.7.3
			export HADOOP_HOME
	
			PATH=$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$PATH
			export PATH
			生效环境变量
			source ~/.bash_profile	
			
	（*）免密码登录
	
	1、本地模式
		特点：没有HDFS和Yarn，测试MapReduce程序
		hadoop-env.sh
			export JAVA_HOME=/root/training/jdk1.8.0_181
	
	2、伪分布模式
		特点：在单机上模拟一个分布式的环境；具备Hadoop的所有功能
			  HDFS：NameNode、DataNode、SecondaryNameNode
			  Yarn：ResourceManager、NodeManager
		hdfs-site.xml
			<!--数据块的冗余度-->
			<property>
				<name>dfs.replication</name>
				<value>1</value>
			</property>
	
	        <!--禁用了HDFS的权限检查-->
			<property>
				<name>dfs.permissions</name>
				<value>false</value>
			</property>	
		
		core-site.xml
			<!--NameNode的地址-->
			<!--9000是RPC通信端口-->
			<property>
				<name>fs.defaultFS</name>
				<value>hdfs://bigdata11:9000</value>
			</property>			
	
			<!--HDFS对应的操作系统目录-->
			<property>
				<name>hadoop.tmp.dir</name>
				<value>/root/training/hadoop-2.7.3/tmp</value>
			</property>	
	
		mapred-site.xml
			<property>
				<name>mapreduce.framework.name</name>
				<value>yarn</value>
			</property>			
		
		yarn-site.xml
		    <!--Yarn的主节点-->
			<property>
				<name>yarn.resourcemanager.hostname</name>
				<value>bigdata11</value>
			</property>		
		    
			<!--NodeManager的服务：洗牌-->
			<property>
				<name>yarn.nodemanager.aux-services</name>
				<value>mapreduce_shuffle</value>
			</property>	
	
		对NameNode格式化：
			hdfs namenode -format
	
	3、全分布模式：3台
	
	4、HA模式（high availablilty高可用性）：解决主从架构的单点故障的问题

## 六、HDFS

​	1、操作
​		（*）命令行：操作命令、管理命令
​		（*）Java API
​				(1)创建目录
​				(2)上传文件
​		（*）Web Console
​				NameNode端口：50070
​				SecondaryNameNode端口：50090
​		
​		

	2、架构组成
		（1）NameNode
		    管理和维护HDFS：fsimage、edits
		    主节点，存在单点故障
		    处理客户端的请求
		（2）DataNode
		（3）SecondaryNameNode，不是namenode的备份。必须借助ZOOKEEPER实现HA
			职责：将edits中的最新状态写到fsimage
			检查点（CheckPoint）
			
	3、HDFS的高级特性
		（1）快照snapshot
		（2）安全模式
		（3）回收站
		（4）配额quota
		（5）权限管理

## 七、MapReduce

​	1、运行WordCount程序
​		（*）自带Example：$HADOOP_HOME/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar
​			hadoop jar hadoop-mapreduce-examples-2.7.2.jar wordcount /input/data.txt /output/1008/wc
​			
​			

	2、MapReduce的特性
		（1）序列化：Writable，自定义数据类型
		（2）排序
		（3）分区：（MapReduce默认分区、Spark的核心是RDD：由分区组成）
		（4）******